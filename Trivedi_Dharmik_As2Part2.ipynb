{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOqYOcEOi9HQekC/SbeRQPq",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/trivedidharmik/cs3735/blob/main/Trivedi_Dharmik_As2Part2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Random Forest Class"
      ],
      "metadata": {
        "id": "I3aYh-IMbaV1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from collections import Counter\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import classification_report\n",
        "import pandas as pd\n",
        "\n",
        "class RandomForest:\n",
        "    def __init__(self, nTrees=10, maxDepth=None, minSplit=2, nFeatures=None):\n",
        "        self.nTrees = nTrees\n",
        "        self.maxDepth = maxDepth\n",
        "        self.minSplit = minSplit\n",
        "        self.nFeatures = nFeatures\n",
        "        self.trees = []\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        self.trees = []\n",
        "        nSamples, nFeats = X.shape\n",
        "        self.nFeatures = nFeats if not self.nFeatures else min(self.nFeatures, nFeats)\n",
        "\n",
        "        for _ in range(self.nTrees):\n",
        "            # Create a Decision Tree\n",
        "            tree = DecisionTreeClassifier(\n",
        "                max_depth=self.maxDepth,\n",
        "                min_samples_split=self.minSplit,\n",
        "                max_features=self.nFeatures,\n",
        "            )\n",
        "\n",
        "            # Bootstrap sampling\n",
        "            idxs = np.random.choice(nSamples, nSamples, replace=True)\n",
        "            X_sample, y_sample = X[idxs], y[idxs]\n",
        "\n",
        "            # Train the tree on the bootstrap sample\n",
        "            tree.fit(X_sample, y_sample)\n",
        "\n",
        "            # Add the trained tree to the forest\n",
        "            self.trees.append(tree)\n",
        "\n",
        "    def predict(self, X):\n",
        "        # Predict using each tree\n",
        "        treePreds = np.array([tree.predict(X) for tree in self.trees])\n",
        "        return np.array([self._most_common_label(preds) for preds in treePreds.T])\n",
        "\n",
        "    def _most_common_label(self, y):\n",
        "        counter = Counter(y)\n",
        "        return counter.most_common(1)[0][0]"
      ],
      "metadata": {
        "id": "11jzQiwQV-kZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Execution"
      ],
      "metadata": {
        "id": "V617gvhSbiqW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load the data"
      ],
      "metadata": {
        "id": "BfU-ynN9bINE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/letter-recognition/letter-recognition.data\"\n",
        "column_names = [\"lettr\", \"x-box\", \"y-box\", \"width\", \"height\", \"onpix\", \"x-bar\", \"y-bar\", \"x2bar\", \"y2bar\", \"xybar\", \"x2ybr\", \"xy2br\", \"x-ege\", \"xegvy\", \"y-ege\", \"yegvx\"]\n",
        "data = pd.read_csv(url, header=None, names=column_names)"
      ],
      "metadata": {
        "id": "Mx_zIi17WToK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Preprocess the data"
      ],
      "metadata": {
        "id": "VMz1fAM-a51t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = data.drop(\"lettr\", axis=1).values\n",
        "y = data[\"lettr\"].values\n",
        "le = LabelEncoder()\n",
        "yEncoded = le.fit_transform(y)"
      ],
      "metadata": {
        "id": "jEg3TRz5XXPE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Split the data and train"
      ],
      "metadata": {
        "id": "G-QSMEcHa8Eh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, yEncoded, test_size=0.3, random_state=42)\n",
        "rf = RandomForest(nTrees=10, maxDepth=10, minSplit=2, nFeatures=5)\n",
        "rf.fit(X_train, y_train)\n",
        "yPred = rf.predict(X_test)"
      ],
      "metadata": {
        "id": "L2jw29KdXaWN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Evaluate the model"
      ],
      "metadata": {
        "id": "H0BoDXK3bFS_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy = np.mean(yPred == y_test)\n",
        "print(f\"Random Forest Accuracy: {accuracy:.4f}\")\n",
        "print(\"Classification Report:\\n\", classification_report(y_test, yPred, target_names=le.classes_))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pXs_4YksXgHq",
        "outputId": "46f05af0-a443-4516-9375-956fd46ceb63"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random Forest Accuracy: 0.8017\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           A       0.99      0.93      0.96       232\n",
            "           B       0.49      0.70      0.58       229\n",
            "           C       0.91      0.81      0.86       201\n",
            "           D       0.73      0.79      0.76       250\n",
            "           E       0.82      0.63      0.71       238\n",
            "           F       0.86      0.77      0.81       211\n",
            "           G       0.67      0.86      0.75       230\n",
            "           H       0.83      0.48      0.61       218\n",
            "           I       1.00      0.79      0.88       221\n",
            "           J       0.99      0.76      0.86       228\n",
            "           K       0.60      0.81      0.69       188\n",
            "           L       0.99      0.85      0.91       231\n",
            "           M       0.96      0.87      0.91       252\n",
            "           N       0.89      0.82      0.86       231\n",
            "           O       0.73      0.78      0.75       218\n",
            "           P       0.86      0.86      0.86       248\n",
            "           Q       0.66      0.76      0.71       253\n",
            "           R       0.45      0.90      0.60       234\n",
            "           S       0.81      0.75      0.78       235\n",
            "           T       0.95      0.83      0.89       232\n",
            "           U       0.99      0.76      0.86       261\n",
            "           V       0.93      0.90      0.91       237\n",
            "           W       0.95      0.92      0.94       213\n",
            "           X       0.78      0.85      0.81       245\n",
            "           Y       0.95      0.83      0.89       251\n",
            "           Z       0.95      0.81      0.87       213\n",
            "\n",
            "    accuracy                           0.80      6000\n",
            "   macro avg       0.84      0.80      0.81      6000\n",
            "weighted avg       0.84      0.80      0.81      6000\n",
            "\n"
          ]
        }
      ]
    }
  ]
}